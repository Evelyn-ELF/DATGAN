{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.1.1\n"
     ]
    }
   ],
   "source": [
    "import datgan\n",
    "print(datgan.__version__)\n",
    "\n",
    "from datgan import DATGAN\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import tensorflow as tf\n",
    "\n",
    "# Run the model eagerly\n",
    "#tf.config.run_functions_eagerly(True)\n",
    "\n",
    "# For the Python notebook\n",
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load the original data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/CMAP.csv', index_col=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>choice</th>\n",
       "      <th>travel_dow</th>\n",
       "      <th>trip_purpose</th>\n",
       "      <th>distance</th>\n",
       "      <th>hh_vehicles</th>\n",
       "      <th>hh_size</th>\n",
       "      <th>hh_bikes</th>\n",
       "      <th>hh_descr</th>\n",
       "      <th>hh_income</th>\n",
       "      <th>gender</th>\n",
       "      <th>age</th>\n",
       "      <th>license</th>\n",
       "      <th>education_level</th>\n",
       "      <th>work_status</th>\n",
       "      <th>departure_time</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>drive</td>\n",
       "      <td>7</td>\n",
       "      <td>HOME_OTHER</td>\n",
       "      <td>3.93477</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>detached</td>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>30</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>PTE</td>\n",
       "      <td>20.166667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>drive</td>\n",
       "      <td>2</td>\n",
       "      <td>SHOPPING</td>\n",
       "      <td>0.31557</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>detached</td>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>54</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>FTE</td>\n",
       "      <td>17.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>drive</td>\n",
       "      <td>2</td>\n",
       "      <td>SHOPPING</td>\n",
       "      <td>0.28349</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>detached</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>80</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>PTE</td>\n",
       "      <td>9.333333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>drive</td>\n",
       "      <td>2</td>\n",
       "      <td>OTHER</td>\n",
       "      <td>0.69417</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>detached</td>\n",
       "      <td>5</td>\n",
       "      <td>1</td>\n",
       "      <td>42</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>FTE</td>\n",
       "      <td>13.783333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>passenger</td>\n",
       "      <td>1</td>\n",
       "      <td>SHOPPING</td>\n",
       "      <td>4.30666</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>detached</td>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>32</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Unemployed</td>\n",
       "      <td>11.566667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      choice  travel_dow trip_purpose  distance  hh_vehicles  hh_size  \\\n",
       "0      drive           7   HOME_OTHER   3.93477            2        3   \n",
       "1      drive           2     SHOPPING   0.31557            3        3   \n",
       "2      drive           2     SHOPPING   0.28349            1        1   \n",
       "3      drive           2        OTHER   0.69417            2        2   \n",
       "4  passenger           1     SHOPPING   4.30666            2        2   \n",
       "\n",
       "   hh_bikes  hh_descr  hh_income  gender  age  license  education_level  \\\n",
       "0         3  detached          6       0   30        1                4   \n",
       "1         3  detached          7       0   54        1                5   \n",
       "2         0  detached          3       0   80        1                3   \n",
       "3         0  detached          5       1   42        1                5   \n",
       "4         1  detached          4       0   32        0                3   \n",
       "\n",
       "  work_status  departure_time  \n",
       "0         PTE       20.166667  \n",
       "1         FTE       17.500000  \n",
       "2         PTE        9.333333  \n",
       "3         FTE       13.783333  \n",
       "4  Unemployed       11.566667  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Provide information on the data\n",
    "\n",
    "We need to provide the data type for each columns and give a bit more information about continuous columns.\n",
    "\n",
    "In our case, the `distance` is an exponential distriubtion => we transform it using a logarithm in order to make it easier for the generator to learn the distribution."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, define the specificities of continuous variables\n",
    "data_info = {\n",
    "    'distance': {\n",
    "        'type': 'continuous',\n",
    "        'bounds': [0.0, np.infty],\n",
    "        'discrete': False,\n",
    "        'apply_func': (lambda x: np.log(x+1)),\n",
    "    },\n",
    "    'age': {\n",
    "        'type': 'continuous',\n",
    "        'bounds': [0, 100],\n",
    "        'enforce_bounds': True,\n",
    "        'discrete': True\n",
    "    },\n",
    "    'departure_time': {\n",
    "        'type': 'continuous',\n",
    "        'bounds': [0, 23.999],\n",
    "        'discrete': False\n",
    "    }\n",
    "}\n",
    "\n",
    "# Add the other variables as categorical\n",
    "for c in df.columns:\n",
    "    if c not in data_info.keys():\n",
    "        data_info[c] = {'type': 'categorical'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DAG\n",
    "\n",
    "We need to define the DAG using the library `networkx`. \n",
    "\n",
    "```\n",
    "We highly recommend creating this DAG using a \"drawing\" tool in order to better visualize the DAG. It will be easier to create it this way.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "graph = nx.DiGraph()\n",
    "graph.add_edges_from([\n",
    "    (\"age\", \"license\"),\n",
    "    (\"age\", \"education_level\"),\n",
    "    (\"gender\", \"work_status\"),\n",
    "    (\"education_level\", \"work_status\"),\n",
    "    (\"education_level\", \"hh_income\"),\n",
    "    (\"work_status\", \"hh_income\"),\n",
    "    (\"hh_income\", \"hh_descr\"),\n",
    "    (\"hh_income\", \"hh_size\"),\n",
    "    (\"hh_size\", \"hh_vehicles\"),\n",
    "    (\"hh_size\", \"hh_bikes\"),\n",
    "    (\"work_status\", \"trip_purpose\"),\n",
    "    (\"trip_purpose\", \"departure_time\"),\n",
    "    (\"trip_purpose\", \"distance\"),\n",
    "    (\"travel_dow\", \"choice\"),\n",
    "    (\"distance\", \"choice\"),\n",
    "    (\"departure_time\", \"choice\"),\n",
    "    (\"hh_vehicles\", \"choice\"),\n",
    "    (\"hh_bikes\", \"choice\"),\n",
    "    (\"license\", \"choice\"),\n",
    "    (\"education_level\", \"hh_size\"),\n",
    "    (\"work_status\", \"hh_descr\"),\n",
    "    (\"work_status\", \"hh_size\"),\n",
    "    (\"hh_income\", \"hh_bikes\"),\n",
    "    (\"hh_income\", \"hh_vehicles\"),\n",
    "    (\"trip_purpose\", \"choice\")\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choosing the right batch size allows to not waste data while training the models\n",
    "batch_size = 1116"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train the DATGAN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = './output/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "datgan = DATGAN(output=output_folder, batch_size=batch_size, num_epochs=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is possible to preprocess the data and save it somewhere. Since it takes a bit of time to do it, it helps to test multiple models faster. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessing the data!\n",
      "Encoding categorical variable \"choice\"...\n",
      "Encoding categorical variable \"travel_dow\"...\n",
      "Encoding categorical variable \"trip_purpose\"...\n",
      "Encoding continuous variable \"distance\"...\n",
      "Encoding categorical variable \"hh_vehicles\"...\n",
      "Encoding categorical variable \"hh_size\"...\n",
      "Encoding categorical variable \"hh_bikes\"...\n",
      "Encoding categorical variable \"hh_descr\"...\n",
      "Encoding categorical variable \"hh_income\"...\n",
      "Encoding categorical variable \"gender\"...\n",
      "Encoding continuous variable \"age\"...\n",
      "Encoding categorical variable \"license\"...\n",
      "Encoding categorical variable \"education_level\"...\n",
      "Encoding categorical variable \"work_status\"...\n",
      "Encoding continuous variable \"departure_time\"...\n",
      "Preprocessed data have been saved in './encoded_data'\n"
     ]
    }
   ],
   "source": [
    "datgan.preprocess(df, data_info, preprocessed_data_path='./encoded_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If the data has been preprocessed, you need to provide the path where it was saved. The model will then load the preprocessed data and work with it. If no preprocessed data are found in the specified folder, the model will still preprocess them before training the networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data have been loaded!\n",
      "Start training DATGAN with the WGAN loss (21/03/2022 15:08:31).\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training DATGAN: 100%|█████████████████████████████████████████████████████████████| 1000/1000 [23:35<00:00,  1.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATGAN has finished training (21/03/2022 15:32:06) - Training time: 23 minutes and 35 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "datgan.fit(df, data_info, graph, preprocessed_data_path='./encoded_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sample the synthetic data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling from DATGAN: 100%|██████████████████████████████████████████████████████| 8929/8929 [00:02<00:00, 3793.09it/s]\n"
     ]
    }
   ],
   "source": [
    "samples = datgan.sample(len(df))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Save the new dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.to_csv('./data/DATGAN.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample with conditionals\n",
    "\n",
    "You can use simple conditionals while sampling data after training the DATGAN. You need to provide information in a dictionary:\n",
    "- **categorical variables:** Provide a string or a list of string elemets corresponding the categories you want to get\n",
    "- **continuous variables:** Provide a lambda function that returns a boolean value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond_dict = {'choice': ['cycle', 'passenger'], 'age': lambda x: x<30}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling from DATGAN: 100%|███████████████████████████████████████████████████████| 8929/8929 [00:34<00:00, 255.18it/s]\n"
     ]
    }
   ],
   "source": [
    "samples = datgan.sample(len(df), cond_dict=cond_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.to_csv('./data/DATGAN_cond.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Train DATGAN with conditional inputs\n",
    "\n",
    "The DATGAN has been upgraded such that you can train it using some of the columns in the dataset as *conditional inputs*. This means that the specified variables will not be generated by the DATGAN. This allows to input data coming from a different dataset in the DATGAN as inputs for the sampling process. The model will then generate the remaining variables.\n",
    "\n",
    "In order to use the conditional inputs, you *do not* need to change the DAG or the encoded data. You just need to add a list of conditional inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_folder = './output_cond/'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "datgan_cond = DATGAN(output=output_folder, \n",
    "                     batch_size=batch_size,\n",
    "                     conditional_inputs = ['age', 'gender', 'trip_purpose'],\n",
    "                     num_epochs=1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Preprocessed data have been loaded!\n",
      "Start training DATGAN with the WGAN loss (17/03/2022 15:38:55).\n",
      "Restored models from epoch 1000.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Training DATGAN: 0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DATGAN has finished training (17/03/2022 15:38:55) - Training time: 00 second\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "datgan_cond.fit(df, data_info, graph, preprocessed_data_path='./encoded_data')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In order to sample synthetic data, we need to provide a dataset containing the variables the variables given as conditional inputs. If we want to generate the same dataset as the original one, you can simply pass the corresponding columns of the original dataset as inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = df[datgan_cond.conditional_inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling from DATGAN: 100%|██████████████████████████████████████████████████████| 8929/8929 [00:03<00:00, 2803.05it/s]\n"
     ]
    }
   ],
   "source": [
    "samples = datgan_cond.sample(len(df), inputs=cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.to_csv('./data/DATGAN_ci.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As said earlier, it is possible to pass a modified dataset as the input for sampling the model. You do not need to care about the size of this given dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "cond = cond[cond['gender'] == 0]\n",
    "cond = cond[cond['trip_purpose'] == 'HOME_WORK']\n",
    "cond.index = range(len(cond))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling from DATGAN: 100%|██████████████████████████████████████████████████████| 8929/8929 [00:02<00:00, 3773.48it/s]\n"
     ]
    }
   ],
   "source": [
    "samples = datgan_cond.sample(len(df), inputs=cond)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.to_csv('./data/DATGAN_ci_cond.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample with conditionals\n",
    "\n",
    "It is also possible to use the rejection sampling process while sampling the DATGAN with conditional inputs. In this case, the variable `age` is conditioned using the rejection sampling. However, it could also be conditioned by updating the input DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Sampling from DATGAN: 100%|████████████████████████████████████████████████████████| 8929/8929 [03:58<00:00, 37.37it/s]\n"
     ]
    }
   ],
   "source": [
    "samples = datgan_cond.sample(len(df), inputs=cond, cond_dict=cond_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "samples.to_csv('./data/DATGAN_ci_double_cond.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "dev"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
